{
  "run_id": "20260129-032656_c838c9",
  "timestamp": "2026-01-29T03:26:56.119512+00:00",
  "model": "llama3.1:8b-instruct-q8_0",
  "prompt_text": "Summarize the key tradeoffs between unified memory and discrete VRAM for local LLM inference.",
  "prompt_hash": "a5c962a58989ea4e18417ada631daff30b78c23239e636c2df1ffe2f88454a46",
  "settings": {
    "max_tokens": 256,
    "temperature": 0.2,
    "num_ctx": 4096,
    "repeat": 1,
    "machine_ids": null
  },
  "central_git_sha": "4a73a02fa82b485b77d5ebe7628f2d2ec3826e6f",
  "machines": [
    {
      "machine_id": "macbook",
      "label": "Macbook Pro (M4, 128GB)",
      "status": "complete",
      "job_id": "bfb96b1d-0331-4a8a-9ad5-3455f65bb612",
      "model_fit": {
        "status": "unknown",
        "needed_gb": 14.0,
        "available_gb": null,
        "memory_label": "RAM"
      },
      "ttft_ms": 886.6574590000021,
      "tok_s": 39.27728486603665,
      "total_ms": 5469.4589590000005,
      "tokens": 180,
      "engine": "ollama",
      "model": "llama3.1:8b-instruct-q8_0",
      "fallback_reason": null
    }
  ],
  "updated_at": "2026-01-29T03:27:01.670274+00:00"
}