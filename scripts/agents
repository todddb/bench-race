#!/usr/bin/env bash
set -euo pipefail

# shellcheck source=scripts/_common.sh
source "$(cd "$(dirname "$0")" && pwd)/_common.sh"

CMD="${1:-}"
shift || true

PIDFILE="${RUN_DIR}/agent.pid"
LOGFILE="${LOG_DIR}/agent.log"
OLLAMA_PIDFILE="${RUN_DIR}/ollama.pid"
OLLAMA_LOGFILE="${LOG_DIR}/ollama.log"
COMFYUI_PIDFILE="${RUN_DIR}/comfyui.pid"
COMFYUI_LOGFILE="${LOG_DIR}/comfyui.log"

AGENT_HOST="${AGENT_HOST:-0.0.0.0}"
AGENT_PORT="${AGENT_PORT:-9001}"
OLLAMA_HOST="${OLLAMA_HOST:-127.0.0.1}"
OLLAMA_PORT="${OLLAMA_PORT:-11434}"
OLLAMA_URL="http://${OLLAMA_HOST}:${OLLAMA_PORT}"

# ComfyUI settings - read from agent.yaml or use defaults
COMFYUI_DIR="${COMFYUI_DIR:-${REPO_ROOT}/agent/third_party/comfyui}"
COMFYUI_PORT="${COMFYUI_PORT:-8188}"
COMFYUI_HOST="${COMFYUI_HOST:-0.0.0.0}"

# Try to read ComfyUI config from agent.yaml
if [[ -f "${REPO_ROOT}/agent/config/agent.yaml" ]]; then
  COMFYUI_ENABLED="$(python3 -c "import yaml; c=yaml.safe_load(open('${REPO_ROOT}/agent/config/agent.yaml')); print(c.get('comfyui', {}).get('enabled', True))" 2>/dev/null || echo "True")"
  if [[ "${COMFYUI_ENABLED}" == "False" ]]; then
    COMFYUI_ENABLED="false"
  else
    COMFYUI_ENABLED="true"
  fi
  COMFYUI_PORT="$(python3 -c "import yaml; c=yaml.safe_load(open('${REPO_ROOT}/agent/config/agent.yaml')); print(c.get('comfyui', {}).get('port', 8188))" 2>/dev/null || echo "8188")"
else
  COMFYUI_ENABLED="true"
fi

usage() {
  cat <<EOF
Usage: $(basename "$0") <command> [--daemon]

Commands:
  start       Start agent (and ensure Ollama + ComfyUI)
  stop        Stop agent (and ComfyUI if we started it)
  status      Show status of agent, ollama, and comfyui with GPU/CPU info
  restart     Stop then start
  logs        Tail agent log

Env:
  AGENT_HOST, AGENT_PORT
  OLLAMA_HOST, OLLAMA_PORT
  COMFYUI_DIR, COMFYUI_PORT, COMFYUI_HOST
EOF
}

is_listening() {
  local port="$1"
  lsof -nP -iTCP:"${port}" -sTCP:LISTEN >/dev/null 2>&1
}

ensure_ollama() {
  if ! command -v ollama >/dev/null 2>&1; then
    log "WARN: 'ollama' not found in PATH. Agent will fallback to mock backend."
    return 0
  fi

  if curl -fsS "${OLLAMA_URL}/api/tags" >/dev/null 2>&1; then
    log "Ollama reachable at ${OLLAMA_URL}"
    return 0
  fi

  # Port already listening? Don't start another.
  if is_listening "${OLLAMA_PORT}"; then
    log "Ollama already listening on ${OLLAMA_HOST}:${OLLAMA_PORT}; waiting for API..."
  else
    # Existing process?
    local existing
    existing="$(pgrep -f "ollama serve" || true)"
    if [[ -n "${existing}" ]]; then
      log "Ollama serve already running (pid(s) ${existing}); waiting for API..."
    else
      log "Starting Ollama (ollama serve) ..."
      nohup ollama serve >> "${OLLAMA_LOGFILE}" 2>&1 &
      write_pid "${OLLAMA_PIDFILE}" "$!"
    fi
  fi

  for _ in {1..50}; do
    if curl -fsS "${OLLAMA_URL}/api/tags" >/dev/null 2>&1; then
      log "Ollama is now reachable at ${OLLAMA_URL}"
      return 0
    fi
    sleep 0.2
  done

  log "WARN: Ollama still not reachable at ${OLLAMA_URL}. Agent may fallback to mock."
  return 0
}

check_comfyui_health() {
  curl -fsS --max-time 2 "http://127.0.0.1:${COMFYUI_PORT}/system_stats" >/dev/null 2>&1
}

ensure_comfyui() {
  if [[ "${COMFYUI_ENABLED}" != "true" ]]; then
    log "ComfyUI disabled in config."
    return 0
  fi

  log "Checking ComfyUI..."

  # Check if already running and healthy
  local pid
  pid="$(read_pid "${COMFYUI_PIDFILE}")"
  if [[ -n "${pid}" ]] && pid_is_running "${pid}"; then
    if check_comfyui_health; then
      log "ComfyUI already running and healthy at http://127.0.0.1:${COMFYUI_PORT}"
      return 0
    fi
  fi

  # Check if port is already listening (maybe started externally)
  if is_listening "${COMFYUI_PORT}"; then
    if check_comfyui_health; then
      log "ComfyUI already running at http://127.0.0.1:${COMFYUI_PORT}"
      return 0
    fi
  fi

  # Need to start ComfyUI
  if [[ ! -d "${COMFYUI_DIR}" ]]; then
    log "WARN: ComfyUI directory not found: ${COMFYUI_DIR}"
    log "Run scripts/install_comfyui_linux.sh or scripts/install_comfyui_macos.sh to install."
    return 1
  fi

  if [[ ! -d "${COMFYUI_DIR}/.venv" ]]; then
    log "WARN: ComfyUI venv not found: ${COMFYUI_DIR}/.venv"
    log "Run scripts/install_comfyui_linux.sh or scripts/install_comfyui_macos.sh to install."
    return 1
  fi

  log "Starting ComfyUI on ${COMFYUI_HOST}:${COMFYUI_PORT}..."

  # Start ComfyUI
  (
    cd "${COMFYUI_DIR}"
    nohup "${COMFYUI_DIR}/.venv/bin/python" main.py --listen "${COMFYUI_HOST}" --port "${COMFYUI_PORT}" >> "${COMFYUI_LOGFILE}" 2>&1 &
    echo "$!" > "${COMFYUI_PIDFILE}"
  )

  pid="$(read_pid "${COMFYUI_PIDFILE}")"
  log "ComfyUI started (pid ${pid}). Waiting for health check..."

  # Wait for health check (up to 10 seconds)
  local count=0
  while [[ ${count} -lt 20 ]]; do
    if ! pid_is_running "${pid}"; then
      log "ERROR: ComfyUI process exited unexpectedly."
      log "--- Last 50 lines of ${COMFYUI_LOGFILE} ---"
      tail -n 50 "${COMFYUI_LOGFILE}" 2>/dev/null || true
      log "--- End of log ---"
      rm -f "${COMFYUI_PIDFILE}" || true
      return 1
    fi

    if check_comfyui_health; then
      log "ComfyUI healthy at http://127.0.0.1:${COMFYUI_PORT}"
      return 0
    fi

    sleep 0.5
    count=$((count + 1))
  done

  # Timeout
  if pid_is_running "${pid}"; then
    log "ERROR: ComfyUI did not become healthy within 10s."
    log "Process is still running but not responding to health checks."
  else
    log "ERROR: ComfyUI process died during startup."
  fi
  log "--- Last 50 lines of ${COMFYUI_LOGFILE} ---"
  tail -n 50 "${COMFYUI_LOGFILE}" 2>/dev/null || true
  log "--- End of log ---"
  return 1
}

stop_comfyui() {
  local pid
  pid="$(read_pid "${COMFYUI_PIDFILE}")"
  if [[ -z "${pid}" ]]; then
    return 0
  fi
  if pid_is_running "${pid}"; then
    log "Stopping ComfyUI (pid ${pid})..."
    kill "${pid}" || true

    for _ in {1..20}; do
      if ! pid_is_running "${pid}"; then
        break
      fi
      sleep 0.2
    done

    if pid_is_running "${pid}"; then
      log "ComfyUI still running; sending SIGKILL..."
      kill -9 "${pid}" || true
    fi
  fi
  rm -f "${COMFYUI_PIDFILE}" || true
}

detect_ollama_accel() {
  # Returns: gpu, cpu, unknown, or down
  if ! curl -fsS "${OLLAMA_URL}/api/tags" >/dev/null 2>&1; then
    echo "down"
    return
  fi

  # Try nvidia-smi to check if ollama is using GPU
  if command -v nvidia-smi >/dev/null 2>&1; then
    local gpu_procs
    gpu_procs="$(nvidia-smi --query-compute-apps=process_name,used_memory --format=csv,noheader,nounits 2>/dev/null || true)"
    if echo "${gpu_procs}" | grep -qi "ollama"; then
      echo "gpu"
      return
    fi
    # nvidia-smi exists but no ollama using GPU
    echo "cpu"
    return
  fi

  echo "unknown"
}

detect_comfyui_accel() {
  # Returns: gpu, cpu, unknown, or down
  if ! check_comfyui_health; then
    if ! is_listening "${COMFYUI_PORT}"; then
      echo "down"
      return
    fi
  fi

  # Check log for device info
  if [[ -f "${COMFYUI_LOGFILE}" ]]; then
    local log_tail
    log_tail="$(tail -n 200 "${COMFYUI_LOGFILE}" 2>/dev/null | tr '[:upper:]' '[:lower:]' || true)"
    if echo "${log_tail}" | grep -qE "device: cuda:|using device: cuda"; then
      echo "gpu"
      return
    fi
    if echo "${log_tail}" | grep -qE "device: mps|using device: mps"; then
      echo "gpu"
      return
    fi
    if echo "${log_tail}" | grep -q "torch not compiled with cuda enabled"; then
      echo "cpu"
      return
    fi
    if echo "${log_tail}" | grep -qE "device: cpu|using device: cpu"; then
      echo "cpu"
      return
    fi
  fi

  echo "unknown"
}

start_agent() {
  local pid
  pid="$(read_pid "${PIDFILE}")"
  if [[ -n "${pid}" ]] && pid_is_running "${pid}"; then
    log "Agent already running (pid ${pid})."
    return 0
  fi

  log "Checking Ollama..."
  ensure_ollama

  # Start ComfyUI (if enabled and installed)
  if ! ensure_comfyui; then
    log "ERROR: ComfyUI failed to start. Aborting agent start."
    return 1
  fi

  activate_venv "agent"

  log "Starting agent on ${AGENT_HOST}:${AGENT_PORT} ..."
  if "${is_daemon}"; then
    nohup uvicorn agent.agent_app:app --host "${AGENT_HOST}" --port "${AGENT_PORT}" >> "${LOGFILE}" 2>&1 &
    write_pid "${PIDFILE}" "$!"
    log "Agent started (pid $(read_pid "${PIDFILE}")). Logs: ${LOGFILE}"
  else
    log "Logs: ${LOGFILE}"
    uvicorn agent.agent_app:app --host "${AGENT_HOST}" --port "${AGENT_PORT}" 2>&1 | tee -a "${LOGFILE}"
  fi
}

stop_agent() {
  local pid
  pid="$(read_pid "${PIDFILE}")"
  if [[ -z "${pid}" ]]; then
    log "Agent not running (no pidfile)."
  elif pid_is_running "${pid}"; then
    log "Stopping agent (pid ${pid})..."
    kill "${pid}" || true

    for _ in {1..30}; do
      if ! pid_is_running "${pid}"; then
        break
      fi
      sleep 0.2
    done

    if pid_is_running "${pid}"; then
      log "Agent still running; sending SIGKILL..."
      kill -9 "${pid}" || true
    fi
  else
    log "Agent pidfile exists but process not running (stale pid ${pid})."
  fi

  rm -f "${PIDFILE}" || true

  # Also stop ComfyUI if we started it
  stop_comfyui

  log "Agent stopped."
}

status_agent() {
  local apid opid cpid
  apid="$(read_pid "${PIDFILE}")"
  opid="$(read_pid "${OLLAMA_PIDFILE}")"
  cpid="$(read_pid "${COMFYUI_PIDFILE}")"

  # Agent status
  if [[ -n "${apid}" ]] && pid_is_running "${apid}"; then
    log "Agent: up (pid ${apid}) port ${AGENT_PORT}"
  else
    log "Agent: down"
  fi

  # Ollama status with GPU/CPU detection
  local ollama_accel
  ollama_accel="$(detect_ollama_accel)"
  if [[ "${ollama_accel}" == "down" ]]; then
    if [[ -n "${opid}" ]] && pid_is_running "${opid}"; then
      log "Ollama: starting (pid ${opid})"
    else
      if is_listening "${OLLAMA_PORT}"; then
        log "Ollama: listening but not responding"
      else
        log "Ollama: down"
      fi
    fi
  else
    local accel_str=""
    if [[ "${ollama_accel}" != "unknown" ]]; then
      accel_str=" (${ollama_accel})"
    fi
    log "Ollama: up${accel_str} ${OLLAMA_URL}"
  fi

  # ComfyUI status with GPU/CPU detection
  local comfyui_accel
  comfyui_accel="$(detect_comfyui_accel)"
  if [[ "${comfyui_accel}" == "down" ]]; then
    if [[ -n "${cpid}" ]] && pid_is_running "${cpid}"; then
      log "ComfyUI: starting (pid ${cpid})"
    else
      log "ComfyUI: down (port ${COMFYUI_PORT})"
    fi
  else
    local accel_str=""
    if [[ "${comfyui_accel}" != "unknown" ]]; then
      accel_str=" (${comfyui_accel})"
    fi
    log "ComfyUI: up${accel_str} port ${COMFYUI_PORT}"
  fi

  log "Agent log: ${LOGFILE}"
  log "Ollama log: ${OLLAMA_LOGFILE}"
  log "ComfyUI log: ${COMFYUI_LOGFILE}"
}

tail_logs() {
  touch "${LOGFILE}"
  tail -n 100 -f "${LOGFILE}"
}

case "${CMD}" in
  start) start_agent ;;
  stop) stop_agent ;;
  status) status_agent ;;
  restart) stop_agent; start_agent ;;
  logs) tail_logs ;;
  ""|help|-h|--help) usage; exit 0 ;;
  *) log "Unknown command: ${CMD}"; usage; exit 2 ;;
esac

