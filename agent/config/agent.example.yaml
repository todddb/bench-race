# agent/config/agent.example.yaml
#
# Per-machine configuration for a bench-race agent.
# This file is intentionally NOT tracked when copied to agent.yaml.
#
# Central controls required models and policies.
# This file only configures how the agent runs and connects to backends.

# Unique ID for this machine (must match central machines.yaml)
machine_id: "example-machine"

# Human-friendly label shown in the UI
label: "Example Machine (GPU / RAM)"

# Address/port the agent HTTP server binds to
bind_host: "0.0.0.0"
bind_port: 9001

# Base URL for the local Ollama instance
ollama_base_url: "http://127.0.0.1:11434"

# Central base URL (used for ComfyUI checkpoint sync)
central_base_url: "http://127.0.0.1:8080"

# Platform metadata for scheduling
architecture: "nvidia_linux"

# ComfyUI configuration
comfyui:
  enabled: true
  host: "127.0.0.1"
  port: 8188
  # Optional: install dir for ComfyUI (used for CPU fallback restart)
  install_dir: "agent/third_party/comfyui"

  # Path where agent caches downloaded checkpoints (before symlinking to ComfyUI)
  # Default: agent/model_cache/comfyui (repo-relative)
  cache_path: "agent/model_cache/comfyui"

  # Path where ComfyUI scans for checkpoints
  # Default: agent/third_party/comfyui/models/checkpoints (repo-relative embedded ComfyUI)
  # Override for system installs: /opt/comfyui/models/checkpoints
  checkpoints_dir: "agent/third_party/comfyui/models/checkpoints"

  # Enable debug logging for ComfyUI /prompt failures
  # Saves full request payloads to logs/debug/ for reproduction
  # Can also be enabled via COMFY_DEBUG=1 environment variable
  debug: true

  # Optional CPU fallback settings
  allow_cpu_fallback: false
  cpu_fallback_on:
    - "cuda_unsupported_arch"

# Runtime sampler configuration (CPU/GPU/VRAM usage)
runtime_sampler:
  enabled: true
  interval_s: 1
  buffer_len: 120
